{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "import wave\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Conv1D, MaxPool1D,MaxPool2D, BatchNormalization, GlobalAvgPool1D, Multiply, GlobalMaxPool1D,\n",
    "                                     Dense, Dropout, Activation, Reshape, Concatenate, Add)\n",
    "from keras.layers import Input\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Model\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block1(x, num_features=8, weight_decay=0):\n",
    "    x = Conv1D(num_features, kernel_size=3, padding='same', use_bias=True,kernel_regularizer=l2(weight_decay), kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "basic1=Lambda(basic_block1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(x, num_features=128, weight_decay=0):\n",
    "    x = Conv1D(num_features, kernel_size=3, padding='same', use_bias=True,kernel_regularizer=l2(weight_decay), kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "basic=Lambda(basic_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_fn(x, amplifying_ratio=16):\n",
    "    shortcut=x\n",
    "    x = GlobalAvgPool1D()(x)\n",
    "    x = Reshape((1, num_features))(x)\n",
    "    x = Dense(num_features * amplifying_ratio, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
    "    x = Dense(num_features, activation='sigmoid', kernel_initializer='glorot_uniform')(x)\n",
    "    x = Multiply()([x,shortcut])\n",
    "    return x\n",
    "se=Lambda(se_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rese_block(x, num_features=128, weight_decay=0, amplifying_ratio=16):\n",
    "    x = basic_block(x,num_features,weight_decay)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(num_features, kernel_size=3, padding='same', use_bias=True,kernel_regularizer=l2(weight_decay), kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    shortcut=x\n",
    "    if amplifying_ratio > 0:\n",
    "        x = se_fn(x, amplifying_ratio)\n",
    "    x = Add()([shortcut, x])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPool1D(pool_size=3)(x)\n",
    "    return x\n",
    "rese=Lambda(rese_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "activation=keras.activations.relu\n",
    "dropout_rate=0.1\n",
    "num_features=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 16000, 8)          32        \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 16000, 8)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 8)           0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 36,136\n",
      "Trainable params: 35,608\n",
      "Non-trainable params: 528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = keras.Sequential()\n",
    "classifier.add(InputLayer(input_shape=(16000,8)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(basic1)\n",
    "classifier.add(MaxPool1D(pool_size=3))\n",
    "classifier.add(rese)\n",
    "classifier.add(rese)\n",
    "classifier.add(rese)\n",
    "classifier.add(rese)\n",
    "classifier.add(GlobalMaxPool1D())\n",
    "classifier.add(Dense(units=256, activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Activation(activation))    \n",
    "classifier.add(Dropout(dropout_rate))\n",
    "classifier.add(Dense(units=8, activation='softmax'))\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import scandir\n",
    "filepaths=[]\n",
    "di = r'C:\\Users\\Niraj\\Desktop\\HVsundarSourceLocalization\\Datasets\\Dataset_gen_reverberent\\testdata'\n",
    "for subdir,dirs,files in os.walk(di):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "        #print(filepath)\n",
    "        filepaths.append(str(filepath))\n",
    "#print(filepaths)\n",
    "print(len(filepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "z=[]\n",
    "X=[]\n",
    "group=[]\n",
    "big_group=[]\n",
    "groupnp=[]\n",
    "count=0\n",
    "for i in filepaths:\n",
    "    x,fs=librosa.load(i,16000)\n",
    "    temp=x[15999:31999]\n",
    "    y=[]\n",
    "    y=temp.tolist()\n",
    "    if(count<8):\n",
    "        group.append(y)\n",
    "    count=count+1\n",
    "    if (count>=8):\n",
    "        count=0\n",
    "        groupnp=np.array(group)\n",
    "        big_group.append(groupnp.T)\n",
    "        group=[]\n",
    "    z.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G=np.array(big_group)\n",
    "len(big_group)\n",
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as kb\n",
    "import math\n",
    "def custom_loss(y_actual,y_predict):\n",
    "    act=kb.flatten(y_actual)\n",
    "    pre=kb.flatten(y_predict)\n",
    "    lossy=-kb.mean((act*kb.log(pre))+((1-act)*(kb.log((1-pre)))))\n",
    "    return lossy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss=custom_loss, optimizer='adam',metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0],\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "y=[1,0,0,0,0,0,0,0]\n",
    "for i in range(8):\n",
    "    for j in range(50):\n",
    "        l.append(y)\n",
    "    y=np.roll(y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5  6  7  8\n",
       "0    1  0  0  0  0  0  0  0\n",
       "1    1  0  0  0  0  0  0  0\n",
       "2    1  0  0  0  0  0  0  0\n",
       "3    1  0  0  0  0  0  0  0\n",
       "4    1  0  0  0  0  0  0  0\n",
       "..  .. .. .. .. .. .. .. ..\n",
       "395  0  0  0  0  0  0  0  1\n",
       "396  0  0  0  0  0  0  0  1\n",
       "397  0  0  0  0  0  0  0  1\n",
       "398  0  0  0  0  0  0  0  1\n",
       "399  0  0  0  0  0  0  0  1\n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(l, columns = ['1','2','3','4','5','6','7','8'])\n",
    "df\n",
    "out=df.to_numpy()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(G, out, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 72s 238ms/step - loss: 0.4080 - categorical_accuracy: 0.1243\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.3406 - categorical_accuracy: 0.2174\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 60s 201ms/step - loss: 0.3338 - categorical_accuracy: 0.2621\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.3330 - categorical_accuracy: 0.2695\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.3056 - categorical_accuracy: 0.2870\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 64s 212ms/step - loss: 0.3046 - categorical_accuracy: 0.3061\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 63s 209ms/step - loss: 0.3022 - categorical_accuracy: 0.3157\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 67s 225ms/step - loss: 0.3045 - categorical_accuracy: 0.3243\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 63s 210ms/step - loss: 0.2963 - categorical_accuracy: 0.3330\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2831 - categorical_accuracy: 0.3430\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 66s 221ms/step - loss: 0.2798 - categorical_accuracy: 0.3530\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 59s 196ms/step - loss: 0.2896 - categorical_accuracy: 0.3589\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 58s 192ms/step - loss: 0.2825 - categorical_accuracy: 0.3644\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 59s 196ms/step - loss: 0.2762 - categorical_accuracy: 0.3696\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2744 - categorical_accuracy: 0.3770\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 57s 189ms/step - loss: 0.2708 - categorical_accuracy: 0.3837\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2842 - categorical_accuracy: 0.3854\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2642 - categorical_accuracy: 0.3897\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 52s 174ms/step - loss: 0.2668 - categorical_accuracy: 0.3952\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.2778 - categorical_accuracy: 0.3993\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2690 - categorical_accuracy: 0.4028\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2685 - categorical_accuracy: 0.4060\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2650 - categorical_accuracy: 0.4095\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.2622 - categorical_accuracy: 0.4126\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.2652 - categorical_accuracy: 0.4157\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 51s 168ms/step - loss: 0.2553 - categorical_accuracy: 0.4177\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 51s 171ms/step - loss: 0.2574 - categorical_accuracy: 0.4221\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.2635 - categorical_accuracy: 0.4240\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 51s 171ms/step - loss: 0.2499 - categorical_accuracy: 0.4264\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 65s 215ms/step - loss: 0.2559 - categorical_accuracy: 0.4287\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 58s 194ms/step - loss: 0.2520 - categorical_accuracy: 0.4315\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 58s 193ms/step - loss: 0.2476 - categorical_accuracy: 0.4347\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 58s 192ms/step - loss: 0.2440 - categorical_accuracy: 0.4374\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 57s 190ms/step - loss: 0.2574 - categorical_accuracy: 0.4393\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 58s 192ms/step - loss: 0.2529 - categorical_accuracy: 0.4414\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 58s 193ms/step - loss: 0.2517 - categorical_accuracy: 0.4443\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.2619 - categorical_accuracy: 0.4462\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.2501 - categorical_accuracy: 0.4477\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 64s 213ms/step - loss: 0.2435 - categorical_accuracy: 0.4492\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 59s 196ms/step - loss: 0.2558 - categorical_accuracy: 0.4513\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 58s 193ms/step - loss: 0.2533 - categorical_accuracy: 0.4527\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 57s 190ms/step - loss: 0.2507 - categorical_accuracy: 0.4538\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2460 - categorical_accuracy: 0.4553\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 62s 205ms/step - loss: 0.2537 - categorical_accuracy: 0.4573\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2377 - categorical_accuracy: 0.4584\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 61s 202ms/step - loss: 0.2610 - categorical_accuracy: 0.4591\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 60s 201ms/step - loss: 0.2504 - categorical_accuracy: 0.4602\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2507 - categorical_accuracy: 0.4617\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2521 - categorical_accuracy: 0.4628\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 60s 199ms/step - loss: 0.2460 - categorical_accuracy: 0.4638\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.2513 - categorical_accuracy: 0.4643\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 58s 194ms/step - loss: 0.2470 - categorical_accuracy: 0.4655\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2468 - categorical_accuracy: 0.4658\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 60s 199ms/step - loss: 0.2361 - categorical_accuracy: 0.4668\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 59s 198ms/step - loss: 0.2486 - categorical_accuracy: 0.4678\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2439 - categorical_accuracy: 0.4691\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 60s 202ms/step - loss: 0.2404 - categorical_accuracy: 0.4705\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.2438 - categorical_accuracy: 0.4717\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 58s 195ms/step - loss: 0.2445 - categorical_accuracy: 0.4728\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2425 - categorical_accuracy: 0.4735\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 60s 202ms/step - loss: 0.2490 - categorical_accuracy: 0.4742\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 60s 199ms/step - loss: 0.2536 - categorical_accuracy: 0.4750\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2394 - categorical_accuracy: 0.4755\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2396 - categorical_accuracy: 0.4764\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.2208 - categorical_accuracy: 0.4776\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 61s 205ms/step - loss: 0.2361 - categorical_accuracy: 0.4787\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2517 - categorical_accuracy: 0.4796\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 61s 203ms/step - loss: 0.2443 - categorical_accuracy: 0.4803\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 60s 201ms/step - loss: 0.2310 - categorical_accuracy: 0.4811\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 61s 204ms/step - loss: 0.2376 - categorical_accuracy: 0.4816\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 58s 192ms/step - loss: 0.2455 - categorical_accuracy: 0.4826\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 54s 181ms/step - loss: 0.2515 - categorical_accuracy: 0.4829\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 52s 172ms/step - loss: 0.2531 - categorical_accuracy: 0.4831\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2354 - categorical_accuracy: 0.4840\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2572 - categorical_accuracy: 0.4842\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 52s 173ms/step - loss: 0.2430 - categorical_accuracy: 0.4846\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 52s 175ms/step - loss: 0.2362 - categorical_accuracy: 0.4853\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2512 - categorical_accuracy: 0.4859\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 58s 194ms/step - loss: 0.2467 - categorical_accuracy: 0.4862\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 52s 172ms/step - loss: 0.2377 - categorical_accuracy: 0.4873\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 64s 214ms/step - loss: 0.2359 - categorical_accuracy: 0.4879\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 63s 211ms/step - loss: 0.2344 - categorical_accuracy: 0.4887\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 58s 194ms/step - loss: 0.2476 - categorical_accuracy: 0.4891\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2425 - categorical_accuracy: 0.4893\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2352 - categorical_accuracy: 0.4898\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 54s 179ms/step - loss: 0.2380 - categorical_accuracy: 0.4904\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 51s 171ms/step - loss: 0.2394 - categorical_accuracy: 0.4914\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2612 - categorical_accuracy: 0.4916\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2461 - categorical_accuracy: 0.4916\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2432 - categorical_accuracy: 0.4920\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 51s 171ms/step - loss: 0.2453 - categorical_accuracy: 0.4925\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 50s 168ms/step - loss: 0.2549 - categorical_accuracy: 0.4928\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 51s 170ms/step - loss: 0.2341 - categorical_accuracy: 0.4929\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.2378 - categorical_accuracy: 0.4933\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 60s 200ms/step - loss: 0.2287 - categorical_accuracy: 0.4939\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.2291 - categorical_accuracy: 0.4947\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 61s 205ms/step - loss: 0.2226 - categorical_accuracy: 0.4956\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 59s 197ms/step - loss: 0.2423 - categorical_accuracy: 0.4962\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 59s 198ms/step - loss: 0.2393 - categorical_accuracy: 0.4967\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 62s 206ms/step - loss: 0.2372 - categorical_accuracy: 0.4973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x141a96f8f60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05751026, 0.11371343, 0.28779036, 0.0345555 , 0.2970432 ,\n",
       "        0.06379473, 0.06247322, 0.0831193 ],\n",
       "       [0.04496359, 0.0854487 , 0.2706964 , 0.02310345, 0.39808142,\n",
       "        0.04933653, 0.04725368, 0.08111612],\n",
       "       [0.02752631, 0.04482456, 0.30800444, 0.01182082, 0.50458366,\n",
       "        0.02085837, 0.03480555, 0.04757628],\n",
       "       [0.05116606, 0.09558781, 0.32009155, 0.02934113, 0.32476056,\n",
       "        0.04881824, 0.06033097, 0.06990366],\n",
       "       [0.04061092, 0.06767315, 0.38258114, 0.01967963, 0.3561626 ,\n",
       "        0.0295666 , 0.05647348, 0.04725244],\n",
       "       [0.03611042, 0.06237203, 0.31573266, 0.01734828, 0.4361737 ,\n",
       "        0.03048025, 0.0439295 , 0.05785309],\n",
       "       [0.04593659, 0.08192167, 0.3450197 , 0.02535423, 0.34516713,\n",
       "        0.03874147, 0.05792618, 0.05993298],\n",
       "       [0.045186  , 0.08410508, 0.2927351 , 0.02366469, 0.3844286 ,\n",
       "        0.04564297, 0.05024398, 0.0739936 ],\n",
       "       [0.03809814, 0.06761709, 0.3001486 , 0.01850527, 0.43234733,\n",
       "        0.03486351, 0.04419588, 0.06422422],\n",
       "       [0.05384927, 0.10712834, 0.31026402, 0.03271756, 0.3030784 ,\n",
       "        0.06038225, 0.05871232, 0.07386781],\n",
       "       [0.01391524, 0.01923698, 0.26032516, 0.00403281, 0.646321  ,\n",
       "        0.00808502, 0.01958689, 0.02849689],\n",
       "       [0.06537727, 0.14675355, 0.20153148, 0.04095728, 0.26008937,\n",
       "        0.10653269, 0.05648342, 0.12227492],\n",
       "       [0.03618072, 0.06636548, 0.2552626 , 0.01662163, 0.47436816,\n",
       "        0.0384913 , 0.03767234, 0.07503773],\n",
       "       [0.04369392, 0.08798946, 0.28198376, 0.02366284, 0.38788208,\n",
       "        0.05562776, 0.04300202, 0.07615808],\n",
       "       [0.06831086, 0.1506587 , 0.22355932, 0.04491295, 0.23808095,\n",
       "        0.10125417, 0.06339636, 0.10982676],\n",
       "       [0.02803058, 0.04480607, 0.33409137, 0.01236901, 0.48008236,\n",
       "        0.01957505, 0.03755252, 0.04349296],\n",
       "       [0.03805229, 0.07387074, 0.21731164, 0.01742031, 0.47646615,\n",
       "        0.04889407, 0.0351922 , 0.09279261],\n",
       "       [0.06899188, 0.1531639 , 0.21891348, 0.0455981 , 0.23400582,\n",
       "        0.10408103, 0.06339893, 0.11184683],\n",
       "       [0.02330016, 0.03760505, 0.27485365, 0.0092082 , 0.5617018 ,\n",
       "        0.01826653, 0.02823973, 0.04682498],\n",
       "       [0.03500208, 0.05811104, 0.3534288 , 0.01712088, 0.41549367,\n",
       "        0.02559166, 0.04678224, 0.04846957],\n",
       "       [0.04483681, 0.09358659, 0.19227408, 0.02190442, 0.4241777 ,\n",
       "        0.06955832, 0.03748834, 0.11617365],\n",
       "       [0.01859641, 0.0292188 , 0.26246676, 0.00684361, 0.6064254 ,\n",
       "        0.01409093, 0.02267182, 0.03968632],\n",
       "       [0.0491208 , 0.09879452, 0.23781781, 0.02586912, 0.3796879 ,\n",
       "        0.06371417, 0.04680452, 0.09819117],\n",
       "       [0.06057971, 0.1295262 , 0.22652888, 0.03619461, 0.29442528,\n",
       "        0.08724016, 0.05584907, 0.10965618],\n",
       "       [0.01933788, 0.03168803, 0.19638664, 0.00608634, 0.6522065 ,\n",
       "        0.01855571, 0.02013624, 0.05560274],\n",
       "       [0.02164245, 0.0369804 , 0.2097309 , 0.00795465, 0.62072486,\n",
       "        0.02162421, 0.02213797, 0.05920462],\n",
       "       [0.05122858, 0.09672266, 0.3086911 , 0.02911184, 0.33114114,\n",
       "        0.05095619, 0.05872155, 0.07342689],\n",
       "       [0.01661427, 0.02216898, 0.40016547, 0.00651369, 0.4977603 ,\n",
       "        0.00701835, 0.02954212, 0.02021673],\n",
       "       [0.03762873, 0.07166585, 0.21842287, 0.01627822, 0.4826707 ,\n",
       "        0.04694214, 0.03546987, 0.09092163],\n",
       "       [0.01746853, 0.02467462, 0.34248406, 0.00663726, 0.5460832 ,\n",
       "        0.00911075, 0.02702096, 0.02652062],\n",
       "       [0.03575692, 0.06445284, 0.26900184, 0.0165072 , 0.46978137,\n",
       "        0.03578841, 0.03872224, 0.06998925],\n",
       "       [0.00670275, 0.00721474, 0.38346782, 0.00202137, 0.57571846,\n",
       "        0.00170857, 0.01527105, 0.00789521],\n",
       "       [0.03861979, 0.07273342, 0.24559999, 0.01813328, 0.45993575,\n",
       "        0.0440645 , 0.03871057, 0.08220265],\n",
       "       [0.07144581, 0.18014602, 0.1398207 , 0.04862333, 0.19412884,\n",
       "        0.16007735, 0.05169619, 0.15406178],\n",
       "       [0.02862896, 0.0528202 , 0.46652457, 0.01680257, 0.34472516,\n",
       "        0.02564305, 0.03682534, 0.02803032],\n",
       "       [0.03760742, 0.06729866, 0.288276  , 0.01799814, 0.44372872,\n",
       "        0.03576008, 0.04243561, 0.06689531],\n",
       "       [0.05894644, 0.11810022, 0.280065  , 0.03580478, 0.2902246 ,\n",
       "        0.06771774, 0.0628249 , 0.08631627],\n",
       "       [0.02816937, 0.05500257, 0.16333325, 0.01100987, 0.5805447 ,\n",
       "        0.04161448, 0.02293931, 0.09738644],\n",
       "       [0.05901095, 0.1305013 , 0.19599013, 0.03411378, 0.3079354 ,\n",
       "        0.09734791, 0.04956812, 0.12553239],\n",
       "       [0.05471353, 0.10768386, 0.28105393, 0.03165143, 0.32041976,\n",
       "        0.06153053, 0.0583623 , 0.08458471],\n",
       "       [0.07563943, 0.17648976, 0.20371222, 0.04304135, 0.21522136,\n",
       "        0.10738893, 0.0591172 , 0.11938977],\n",
       "       [0.06872827, 0.16686472, 0.14734004, 0.04206178, 0.22445685,\n",
       "        0.14587854, 0.05089641, 0.15377332],\n",
       "       [0.04726546, 0.09423442, 0.23762669, 0.02437014, 0.39434734,\n",
       "        0.06054105, 0.04514668, 0.09646814],\n",
       "       [0.03203748, 0.05018914, 0.40761298, 0.01590429, 0.389796  ,\n",
       "        0.01914137, 0.0487831 , 0.03653565],\n",
       "       [0.06787314, 0.14874443, 0.22660275, 0.04438401, 0.24127975,\n",
       "        0.09893751, 0.0635471 , 0.10863135],\n",
       "       [0.05038044, 0.10742567, 0.19639288, 0.02630747, 0.3772431 ,\n",
       "        0.07968035, 0.04233275, 0.12023734],\n",
       "       [0.04556482, 0.0847728 , 0.28501073, 0.02300367, 0.38808274,\n",
       "        0.04695085, 0.05007214, 0.07654238],\n",
       "       [0.01504835, 0.01943511, 0.41143677, 0.00578211, 0.49683136,\n",
       "        0.00579979, 0.02818638, 0.01748014],\n",
       "       [0.03101522, 0.05600978, 0.23612683, 0.0132046 , 0.526513  ,\n",
       "        0.03322057, 0.03153989, 0.07237015],\n",
       "       [0.02992468, 0.04391662, 0.42331624, 0.01305899, 0.39275855,\n",
       "        0.01557475, 0.04963863, 0.03181155],\n",
       "       [0.03105864, 0.04826831, 0.35644302, 0.01288923, 0.44422463,\n",
       "        0.02025214, 0.04426091, 0.0426032 ],\n",
       "       [0.02324168, 0.03424831, 0.37820742, 0.00995652, 0.47489655,\n",
       "        0.01271071, 0.03598775, 0.03075101],\n",
       "       [0.01910665, 0.02993794, 0.22979847, 0.00617894, 0.63094264,\n",
       "        0.01552155, 0.0221855 , 0.04632832],\n",
       "       [0.04867598, 0.10829341, 0.1631239 , 0.02458929, 0.3880993 ,\n",
       "        0.09076056, 0.03660255, 0.13985495],\n",
       "       [0.03818275, 0.06997429, 0.26824945, 0.01812474, 0.45144153,\n",
       "        0.03950308, 0.04079321, 0.07373094],\n",
       "       [0.04818667, 0.08816075, 0.32805285, 0.02688596, 0.34086907,\n",
       "        0.04383458, 0.05812439, 0.06588565],\n",
       "       [0.02819034, 0.04643696, 0.30186844, 0.0121535 , 0.5044551 ,\n",
       "        0.02211731, 0.03491607, 0.04986233],\n",
       "       [0.04473351, 0.07816096, 0.31247193, 0.02039799, 0.3837243 ,\n",
       "        0.03966835, 0.05434397, 0.06649886],\n",
       "       [0.06676913, 0.15222111, 0.19352776, 0.0424682 , 0.24916375,\n",
       "        0.11316899, 0.05650606, 0.126175  ],\n",
       "       [0.02054157, 0.03959098, 0.23614381, 0.00808384, 0.62662697,\n",
       "        0.01477701, 0.02327409, 0.03096178],\n",
       "       [0.0384961 , 0.06410262, 0.37867403, 0.02008199, 0.37105972,\n",
       "        0.02706202, 0.05359969, 0.04692381],\n",
       "       [0.03151795, 0.05606856, 0.25277233, 0.01366305, 0.5128373 ,\n",
       "        0.03169493, 0.03349007, 0.06795584],\n",
       "       [0.05558806, 0.11073109, 0.26380205, 0.03100352, 0.32388145,\n",
       "        0.06645771, 0.05708179, 0.09145433],\n",
       "       [0.05834117, 0.13351518, 0.17107196, 0.0332095 , 0.30895516,\n",
       "        0.10896857, 0.04517797, 0.14076044],\n",
       "       [0.01730418, 0.02575861, 0.28203171, 0.00625762, 0.6006865 ,\n",
       "        0.01113209, 0.02319182, 0.03363741],\n",
       "       [0.03514009, 0.06062923, 0.3096905 , 0.01660933, 0.44757786,\n",
       "        0.02992347, 0.04233902, 0.05809052],\n",
       "       [0.05763395, 0.12188935, 0.22634421, 0.03324982, 0.31665882,\n",
       "        0.08224119, 0.05296269, 0.10901991],\n",
       "       [0.03316285, 0.05559006, 0.3263926 , 0.01551202, 0.44958347,\n",
       "        0.02589262, 0.04206469, 0.05180173],\n",
       "       [0.04081354, 0.07294176, 0.31041592, 0.02062196, 0.405564  ,\n",
       "        0.03707853, 0.04804102, 0.06452318],\n",
       "       [0.03850228, 0.07416254, 0.22583923, 0.01781691, 0.46953458,\n",
       "        0.04782595, 0.03646714, 0.08985136],\n",
       "       [0.03973508, 0.06847828, 0.3383117 , 0.01990304, 0.39465073,\n",
       "        0.03213175, 0.05045956, 0.05632982],\n",
       "       [0.03093994, 0.05072494, 0.33262762, 0.01415246, 0.46062103,\n",
       "        0.02284488, 0.04040416, 0.04768495],\n",
       "       [0.05734036, 0.11364083, 0.28475362, 0.03430103, 0.299679  ,\n",
       "        0.06430937, 0.06179354, 0.08418228],\n",
       "       [0.03884764, 0.07741746, 0.40661636, 0.02416843, 0.32269272,\n",
       "        0.04289661, 0.04423205, 0.0431287 ],\n",
       "       [0.03286645, 0.05738926, 0.28020325, 0.01477865, 0.48490712,\n",
       "        0.03023704, 0.0372601 , 0.0623581 ],\n",
       "       [0.03024436, 0.05354685, 0.24804187, 0.01286026, 0.5258827 ,\n",
       "        0.03038546, 0.03199789, 0.06704058],\n",
       "       [0.02410729, 0.0369972 , 0.33852157, 0.01012283, 0.5039346 ,\n",
       "        0.01529674, 0.03385306, 0.03716661],\n",
       "       [0.04535645, 0.08733154, 0.26018634, 0.02323425, 0.40016758,\n",
       "        0.05207454, 0.04630341, 0.08534592],\n",
       "       [0.03623493, 0.06051184, 0.35648   , 0.01803558, 0.40447447,\n",
       "        0.02665173, 0.04846501, 0.04914641],\n",
       "       [0.0400398 , 0.07569599, 0.2498898 , 0.01916775, 0.44656456,\n",
       "        0.04558236, 0.04038899, 0.08267071],\n",
       "       [0.00537113, 0.00681749, 0.17059807, 0.0012697 , 0.7896959 ,\n",
       "        0.00281997, 0.0073771 , 0.01605067],\n",
       "       [0.05415003, 0.10387821, 0.30523008, 0.03173653, 0.31217363,\n",
       "        0.05543032, 0.06145167, 0.07594954],\n",
       "       [0.06154992, 0.12840086, 0.2508208 , 0.03775601, 0.28195265,\n",
       "        0.08013247, 0.06083198, 0.09855527],\n",
       "       [0.05872425, 0.12159721, 0.24810934, 0.03476907, 0.30344135,\n",
       "        0.07664914, 0.05742616, 0.09928349],\n",
       "       [0.03319518, 0.06328433, 0.20601209, 0.01422881, 0.52214605,\n",
       "        0.04225736, 0.03036528, 0.08851098],\n",
       "       [0.05486534, 0.10749155, 0.26707947, 0.02931659, 0.33056036,\n",
       "        0.06374119, 0.05731795, 0.08962753],\n",
       "       [0.02304417, 0.0370547 , 0.27581027, 0.00908003, 0.56290776,\n",
       "        0.01788847, 0.02808047, 0.04613414],\n",
       "       [0.00638223, 0.0074279 , 0.4505811 , 0.0021806 , 0.51140726,\n",
       "        0.00190661, 0.01393104, 0.00618324],\n",
       "       [0.06074356, 0.12654704, 0.24940981, 0.03686814, 0.28822637,\n",
       "        0.07937082, 0.05973735, 0.09909679],\n",
       "       [0.05360935, 0.10234685, 0.3079629 , 0.03129538, 0.3145101 ,\n",
       "        0.05417952, 0.06126292, 0.07483294],\n",
       "       [0.06004345, 0.12153352, 0.2740375 , 0.03677899, 0.2848574 ,\n",
       "        0.07087487, 0.06305633, 0.08881794],\n",
       "       [0.05489962, 0.11306921, 0.2394332 , 0.03091793, 0.3345604 ,\n",
       "        0.07314316, 0.05233186, 0.10164478],\n",
       "       [0.04383661, 0.08004986, 0.3055791 , 0.02284182, 0.38657892,\n",
       "        0.04175032, 0.05049949, 0.06886382],\n",
       "       [0.05327409, 0.101404  , 0.30964813, 0.03102346, 0.31594613,\n",
       "        0.05341611, 0.06114265, 0.07414541],\n",
       "       [0.04061407, 0.06980298, 0.35464102, 0.02125431, 0.3753578 ,\n",
       "        0.03159807, 0.05312881, 0.05360301],\n",
       "       [0.07051098, 0.15948412, 0.20790061, 0.04732291, 0.22349119,\n",
       "        0.11177461, 0.06307166, 0.11644384],\n",
       "       [0.04900163, 0.09440759, 0.27699324, 0.02647642, 0.3645091 ,\n",
       "        0.0541269 , 0.05194535, 0.08253965],\n",
       "       [0.06135137, 0.13912733, 0.18441705, 0.03635726, 0.28841263,\n",
       "        0.10784645, 0.04984804, 0.13263986],\n",
       "       [0.04998191, 0.09074539, 0.3217645 , 0.02620525, 0.3368216 ,\n",
       "        0.04582106, 0.06036025, 0.06830014],\n",
       "       [0.06584335, 0.14668874, 0.20247522, 0.04027972, 0.25945866,\n",
       "        0.10602093, 0.05742006, 0.12181338]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44614252805709836, 0.4962843060493469]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 23s 75ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47456814964612326, 0.49400758743286133]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
